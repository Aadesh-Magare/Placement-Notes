//Basics :
	the protection to memory is provided in hardware. like protection of user space from each other, os space from user.
	the very basic scheme is using Base and limit registers for each process that defines the valid range of memory for that process, every address generated by cpu is first compared to be within range if it is not proper interrupt are raised. only os can change base limit registers by using previlieged instructions that aren't available to user.

	os executing in kernel mode is given unrestricted access to all memory so that it can access others process memory area also.

//Address Binding :

	address in source code is generally symbolic compiler will bind these symbolic addresses to relocatable addresses.
	the loader will then bind relocatable addresses to actual physical addresses.

	compile time binding :
		absolute code, cant move it, it must reside at the same addresse that was fixed during compile time.
	load time binding :
		compiler generates relocatable code (relative from starting position) and loader can load it at any place. but it can't be moved during running of program, once code is loaded it becomes fixd address.
	execution time binding :
		it can be moved while executing, address is not fixed till the execution time. special hardware support is required for this.

//Logical address vs Physical address :
	
	address generated by cpu is logical address (or virtual address) which must be converted into physical address

	logical address space : range of logical addresses generated by cpu
	physical address space : actual range of address available in memory.

	the runtime mapping from virtual to physical address is done by hardware unit called memory management unit.

	MMU : 
		a base register here is called relocation register. its value is added to every address generated by cpu to get actual physical address.

		user processes always work with logical address, not knowing anything about the physical address. the mapping is done at execution time by MMU.

		user considers process is running in logical address (0 to max) while the MMU maps it with relocation register at execution time.

//Dynamic Loading :
	with dynamic Loading a routine is not loaded until its called. it kept on disk in relocatable form, and execution starts with main routine, when another routine is called then its loaded into memory.

	it doenst require special support from os. programmer can do it with proper coding.

//Dynamic Linking and Shared libraries :
	its mainly used for language library program consists of stubs initally and at execution time when the stub runs it checks if required module is in memory if its not then its brought into memory and stub gets replaced.

	due to this there is only one copy of library in memory instead of having each process containing library code. it saved lot of memory space.

	Shared library :
		having multiple libraries with different version numbers., where programs use whatever library they are compatible with.

	dynamic linking requires support from os since it requires checking presence of library in memory area outside current process.

//Swapping :

	it refers to swapping out processes out of memory when required and loading back. its also called roll out and roll in.

	after a process is swapped out and then swapped in, the location at which it should be swapped in depends on the address binding used, if its execution time binding then it can be placed anywhere else it must be placed at proper location.

	when scheduer schedules a process that swapped out then context switch time for that process is quite high.

	pending I/O of swapped out processes may create problems for new process at that location, so to solve the problem either we can have :
	never swap out a process with waiting I/O or always do I/O on OS buffer so that actual transfer from buffer occurs when process is swapped in.

//Continuous Memory Allocation :
	//Mapping And Protection :
		memory is allocated in continous manner to processes, memory mapping and protection is done by relocation register and limit register. MMU maps it to actual physical address at runtime and checks for validity.

		during context switch, dispatcher loads the relocation register and limit register with correct values.

	//Allocation algorithms :
		First fit :
			allocate the first hole thats large enough to hold the process.
		best fit :
			allocate the smallest hole that big enough to hold the process.
		Worst fit :
			allocate largest hole to the process, it produces larger leftover holes.
		first fit and best fit are better performance wise, first fit is faster.

	//Fragmentation :
		
		External fragmentation :
			small holes are formed between processes due to frequent swap in swap out.nearly 50 % blocks are wasted due to fragmentation. its called 50% rule.
		
		Internal fragmentation :
			if we use some fixed partitions of memory then internal fragmentation may happen
		
		one solution to External fragmentation is compaction i.e. moving all processes to one end to shift all holes on one side. its only possible if execution time binding is done.

//Paging :
	logical address space is divided into pages, and physical memory is divided into page frames, of same size.
	system maintains a page table ,which contains mapping of page no to page frame
	every address generated by cpu has page offset and page no. we get corresponding frame no of page table. we know the address of that page frame, add the page offset to it and we get the actual address.

	page size is determined by hardware and its power of 2, so as to be able to convert logical address to page no. if 2^m is logical address space and page size is 2^n, then m-n bits are used for page no and remaining bits are used for page offset.

	There is no external fragmentation in paging, but its not free from internal fragmentation.

	on average half page is wasted due to internal fragmentation. so smaller pages should be preferred. but as no of pages increase the overhead to manage it also increases, also transfer to disk is better when data size is more.

	There's clear separation between user's view of memory and physical memory. user sees memory as single space while in reality its scattered all over.

	Os also maintains a frame table which has one entry for each frame, which contains details whether frame is free or allocated to which process.

	os also maintains per process page table for doing the address translation when process does a system call, pass a logical address as argument.

	//Implmentation of Paging:
		one basic implementation involves a page table base register (PTBR).
		for each memory access we first access the page table using the PTBR get the actual address and then access it. so each memory access needs two memory access. thats very slow.

		the solution is to use special hardware called translation look-aside buffer (TLB). its associative high speed memory. contains key and value pair. when we search a key in TLB its compared with all other values in parallel so search is very fast.

		TLB is used as cache for page table, it contains few entries from page table but not all. when a memory reference is done, its checked if present in TLB if its found then access is very fast only 10 % slower than direct access. but if not found in TLB (miss) page table in memory must be accessed, and this value is then added to TLB.

		in TLB we can use standard replacement algorithms like LRU. some entries can be fixed in TLB thats called as wired down. typically kernel code is wired down.

		Some TLB store address-space indentifiers (ASIDs) (e.g. PID of process) in each TLB entry. it represent a process. during each access it compares the process with entry in ASIDs if it doesnt match then its treated as TLB miss.

		for effective memory access time to be short we must have good hit ratio.

	//Protection:
		we can use one bit in page table to mark the page as read-only or read-write. so can protect it against illegal access.

		one valid-invalid is also kept in page-table that marks a page valid for a process i.e. if process is large enough to be of n pages and page table has more than n capacity then further pages are invalid for that process.

		but the last page of process might be slight empty, accessing it isnt invalid since its valid page. so the process can access some addresses outside its limit due to internal fragmentation.

	//Shared Pages :
		Reentrant code (Pure code) : the code which doesnt change itself during execution pages of such code can be shared between processes.

//Structure of Page-Table :
	
	1. Hierarchical Paging :
	
		if the logical address space is large then size of page table also becomes huge, then its not possible to store it in memory in continuous fashion.
		one way to do this is using two-level paging i.e. page table is also paged. its called forward mapped page table

		32 bit logical address space with 4 KB (2^12) page size.
		here 20 bits will give page no and remaining 12 bits give offset.

		we can further divide 20 bits into 10 bit page no and 10 bit secondary offset .

		for 64 bit machine Hierarchical paging is not appropriate since it will need 7 level of indirection.

	2. Hashed Page Tables :
		
		the virtual address is hashed to some frame no and its kept in hash table on each address reference we check hash table for its frame no and then refer the actual memory. hashing is used for collision handling.

		//Clustered Page tables: 
			same as hashed page tables except that hash table contains multiple page frames associated with one hash value.
	
	3.	Inverted Page Tables :

		standard page table stores mapping of page no of a process to frame no , since there's lot of repetation, here we keep mapping of frame no to page no of any process, to identify which process page belongs to we also keep an address-space identifier such as PID of process.

		thus address from cpu contains page no and pid of process, then we search page table to find that page no, when found we take index as the frame no and the offset, during this we check pid if the page belongs to this process.

		it reduces memory load but increses access time to huge extent, for each memory reference we need to search the page table.

		there's difficuly in maintaining shared pages, since we have one frame and corresponding one page no, we cant share the frame  with many pages.

//Segmentation :
	
	its memory management scheme that supports users view of memory. a user views memory as various segments, code section, main program, stack, heap etc

	so logical address is collection of segments, each having name. users work with the offsets in segments.

	so logical address is ( segment no and offset )

	to implement this segment table is used that contains segment base and limit. i.e. start and length of a segment.

	segment no from address is used as index in segment table to get the base, offset is added to base and result is checked to be within the limits if so, we get physical address else trap to os.

//segmentation and paging :
	both can be used together, cpu generates logical address thats given to segmentation unit, it produces linear address for each logical address. then the linear address is given to paging unit. which generates physical address.