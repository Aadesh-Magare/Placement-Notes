//Thread :
	it has :
		thread ID, Program counter, register set and stack

	threads of a process share code section, data section and other os resources like open files, signals

	useful in client-server architecture, where a server will create a thread for each client request.

	//Benefits of Multi-threading :
		1. Responsiveness : increases Responsiveness even if some part of process is doing lengthy computation, another thread can respond to user
		2. Resource sharing : its costly to share resources with a process, where threads of a process share resources implicitly
		3. Economy : creation of threads is much cheaper than process. e.g. (in solaris creation is 30x cheaper and context switch is 5x faster when compared to process)
		4. scalability : benefits of multi-threading are large on multi-processor system. multithreading on multi-processor system increases concurrency. 

	//Multi-Core programming :
		Multi-Core means having many processors on single chip, here concurrency is more relative to single core processors.

		tha areas which present challenges for Multi-Core programming:
			1. Dividing activities : divide activity such that they can run separately on diff cores
			2. Balance : diff tasks should be balanced in terms of work done, to ensure no one core is over-burdened.
			3. Data splitting : just like activity data must be divided to accesses and manipulated by diff tasks
			4. Data Dependency : while diff threads are running care must be taken for checking dependecy between the data that they manipulate
			5. Testing and Debugging : testing and Debugging of Multi-Core programms is difficult

//Multithreading Models :

	Deals with relationship between user-level threads and kernel threads.

	1. Many to one Model :
		maps many user level threads to one kernel thread, thread management is done by threading library at user-level, so its efficent.

		but if one thread makes blocking system call entire process will block. also multiple threads cannot run in parallel even on a multi-processor system.

	2. One to One model :
		maps each user level thread to kernel thread.when one thread makes blocking sys call, another thread can run on its place, so more concurrency. multiple threds can run on multiple processors

		creating a user-level thread means creating one kernel thread, so the overhead is large. (linux and windows use one to one model)

	3. Many to Many model :
		maps many user level threads to smaller no of (or equal no of) kernel threads.

		no blocking problem as in many to one model, less overhead in creating user thread than in one to one model

//Issues with Multithreading :

	1. Fork and Exec :
		if some thread of process calls fork, there are two options create new process with all the threads of calling process or just create a process with one thread which called fork. some unix provide both versions of fork

		on exec the entire process is replaced by new code. here all the threads of process disappear not just the exec calling thread.

	2. cancellation of thread :
		sometimes we want to cancell the thread before it completes its work, its called target thread.

		Asynchronous cancellation : one thread immediately kills other thread
		deferred cancellation : one thread indicates that target is to be cancelled. target thread periodically checks whether it should terminate, allowing it to terminate in an orderly fashion.

		aysnchronous cancellation may lead to situation where some resources were granted to target thread and werent freed when its terminated

	3. Signal Handling :
		a signal is generated by some event, its delivered to its destination process, once delivered it must be handled.

		Synchronous signal : the signals which are delivered to the same process which performed operation that caused the signal 
		Asynchronous signal : signal are delivered to different process and genereated by some external event to that process.  (like CTRL + C)

		every singal has some default singal handler that is run by kernel, it can be overriden by user-defined signal handler.

		signals are delivered to processes , so handling signals in multi-threaded program is not straight-forward, there are few choices :
			1. deliver to thread to which signal applies
			2. deliver to every thread
			3. deliver to certain threads
			4. assign a thread to recieve all signals
		Synchronous signals need to be delivered to specific thread.
		aysnchronous signals such as CTRL + C needs to be delivered to every thread. 
		
		in Unix some threads may block certain signals, then those threads wont recieve those signals

		kill(pid, sig) is syscall in unix to signal a process
		pthread_kill(tid, sig) function in PThread to signal a thread.

		windows does not explicitly support signals, it can be emulated using asynchronous procedure call (APC). It allows a specific thread to specify a function that will be called when the thread receives notification of particular event.
		

	4. Thread Pool :

		idea behind thread pool is to create no of threads at process startup and place them into pool, where they wait for work, whenever required we can awaken a thread from pool if its available it not then wait till thread become available in pool. once thread complete work, return it into pool

		servicing a request with existing thread is faster than creating new thread, also it keep restriction on maximum no of threads.

	5. Thread - specific data:

		its the data that thread doesnt want to share with other threads

	6. Scheduler Activations :

		Most of systems which use many to many model keep a data structure between user and kernel threads called as LightWeight Process (LWP). to user threading library LWP appears as virtual processor on which it can Schedule threads. Each LWP is attached to one kernel thread, which is scheduled by os on actual processor. if kernel thread blocks, then the attached LWP and user-thread also blocks.

		once scheme for communication between user-threads and kernel threads is Scheduler Activation :

			kernel provides an application with set of LWP, then application can schedule threads on these virtual processors. here kernel must inform application about certain events, its called as UPCALL. UPCALLs are handled by thread library with UPCALLs handler, the handler runs on LWP. 
			e.g. when a thread is about to block, kernel UPCALLs that a thread is blocking and create new LWP for application, application runs its UPCALLs handler on this LWP. this handler saves the state of blocking thread and uses its LWP for another thread.

			same thing occurs when a blocking process is about to unblock.
			