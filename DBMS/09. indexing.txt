// Heap File (pile) :

	Records in file are stored one after another simply, no ordering. 
	For deletion some bit in record is marked as deleted, searching is brute force.

// Sequential File :

	Records in file are kept in sequential order of some attribute generally primary key.
	Searching is easy since binary search is possible on records within one block, when that block is brought into memory.

	For easy insertion and deletion, a field "next" can be maintained which will point to next record.
	This allows the records to be physically inserted anywhere and still be in sequence logically.
	But after frequent insertion-deletion, the logical sequence will be maintained but physically the records will be distant, which means increased block accesses. 
	Due to this reorganization is required frequently, which will rearrange the records. Such function must be done when the system is idle

	To utilize the deleted space, we can keep the available list, which will have pointers to deleted records.

// The idea is maintain an index above this sequential file, so that the operations on it maybe optimized.
Indices are used to find items easily. It's smaller file (in sorted order), that points to items in actual files

// Index Types :
	// Ordered Index :
		Indices are based on a sorted ordering of the values.

	// Hashed Index :
		Indices are based on the values being distributed uniformly across a range of buckets by hash function.

	// Ordered Index : 
		A file can have different indices corresponding to different search keys.

		// Primary or Clustering Index :
			 The search key of index specifies same order as the sequential order of the file, it is known as primary index or clustering index.

			This entry contains the search key and also a reference to the first data record with that search key value.

			 // Dense Index :
				Index contains entry for each search-key, take up more space, searching is fast

			// Sparse Index :
				Index contains entry for some of search keys only, take up less space, insertion deletion overhead is there.

			Good tradeoff between two is to use sparse with one entry per block, since most of time is for accessing data block on disk, once a block is loaded searching in it is not that costly, so as long as we keep block access to one only it works.

		// Secondary or Non-Clustering Index :
			The search key of index specifies an order different from the sequential order of the file, it is called the secondary index or non-clustering index.

			Indexing on secondary key : cause we may have queries where we dont want to search on primary key but on any other attribute, so its better to have indexing on secondary key as well.

			â€‹A non clustered index just tells us where the data lies, i.e. it gives us a list of virtual pointers or references to the location where the data is actually stored. Data is not physically stored in the order of the index. 

			// secondary indices doesn't have the same ordering as the records in the file, so its not enough to save pointer to first entry of each search key(cause the records in file are sorted on primary key and not secondary key). so we must save pointer to every entry associated with search key. we can use indirection here, secondary indices will point to a block which in turn will point to all entries associated with that key

			so secondary indices must be dense type

		// Multi-level Index : using indirection
			sometimes indices become so large that it has to be stored on disk, if that takes more blocks on disk then searching it becomes costlier, so we use secondary indices for this index file using indirection technique
			Indices with two or more levels are called multilevel indices

	// Hashed Index :
		In sequential file indexing we need to access index file, that involves disk access, which degrades performance

		a hash function will hash an record into address of corresponding block or bucket.
		hash function must be random and uniform

		// Bucket Overflow :
		It can occur due to: 
		1. Insufficient buckets 
		2. Bucket skew (more entries in a bucket even if others have space)

		// Types of Hashing :
		1.closed hashing : in case of overflow, chaining is used (overflow buckets are used for chaining)
		2.open hashing: in case of overflow, technique like linear probing is used, or computing further hash

		1. Static hashing : since the hash function is fixed, the no of buckets is fixed. over time it becomes inefficient. since if buckets are large there is memory waste otherwise there is lot of clashing.
		2. Dynamic hashing : allow modification of hash function to accommodate change in database

	// Ordered Index vs Hashed :
		The choice depends on database requirements
		Hashing is very inefficient for range queries, so its used only when dbms has very rare range queries otherwise ordered indexing is used

// B+ Tree : 887

	Imposes insertion, deletion and space overhead but its acceptable when its advantages are taken into account.

	For n order tree, a node (internal) contains n-1 values (search key values on which indexing is done) and n pointers
	e.g.
		for 3 order tree the node will be like:

					3 	  5 
				  |	   |	|
			 	  P1   P2   P3

		P1 is pointer to node with values >= min and < 3
		P2 is pointer to node with values >= 3 and < 5
		P3 is pointer to node with values >= 5 and < max

	In case of leaf node the pointer (Pi) will directly point to that particular record (or that block) with search key (Ki) inside the file, if its unique search key (dense indexing). if it's not then Pi will point to bucket of pointers that will further point to records

	All index nodes (non-leaf) must have at least ceil(n/2) nodes pointers (non-null).
	Each node is of the size of a block. 
	All leaf nodes are at same depth 

// B tree :
	Self-Balancing search trees, deals with huge data that can't fit in memory and has to be read from hard disk in terms of blocks.

	Here internal nodes also store values as opposed to b+ trees.
	so a node will contains pointers to keys less than its key, greater than its key just like B+ tree but also it will contain direct pointer to record with search key equal to its value.

	Main idea of B-tree is to reduce no of disk accesses.
	It's fat tree, height is kept minimum and most operations are of O(h).
	All leaves are at same level.

	For B-tree of degree n :
		It must have  at least n children.
		n depends on block size.
		every node except root must contain at least n-1 keys.
		A node may contain at max 2n-1 keys.
		Number of children = no of keys + 1.

	// Insertion :
		only condition is a node should not overflow on insertion i.e. it should not have more than 2n-1 keys. If it happens, split the node into two nodes and shift the middle key to parent. follow the same steps recursively if parent overflows due to this shift.

	// Deletion :
		// For leaf node :
			if node will not have underflow (less than n-1 keys) because of deletion, simply delete it.
			if it can cause underflow :
			
			case 1 : if key can be borrowed from either sibling node, borrow it with the help of parent.
			case 2 : if key can't be borrowed from sibling (because they have minimum no of keys) merge the node with sibling node, borrow a key from parent which will be the middle key  for this merged node.

		// For internal node :
			case 1 : if the target node has immediate left child from which largest key can be borrowed then borrow the key from child and simply delete the target key.
			case 2 : if the target node has immediate right child from which smallest key can be borrowed then borrow the key from child and simply delete the target key.
			

// Concurrency in Indexed structures :
	to ensure this, b+ tree structure is modified a bit, now every node contains a pointer to its right sibling. (in normal B+ trees only leaf node contains pointer to right sibling)

	a node must be locked in shared mode before its accessed, and lock is released before any other lock is requested

	if a node split occurs during a lookup(search) is going on (due to two concurrent instructions) then our desired value may no longer appear in the same node as before the split. in such case the right pointer is used to traverse sibling nodes until you find it

	for insertion and deletion shared mode lock is converted into exclusive, in case parent needs to be updated then lock on parent is requested

	Coalescence : when node has too few keys its merged with its sibling, for this the sibling is locked in exclusive mode after the coalescence parent is updated by taking exclusive lock

	lookup and insertion cannot lead to deadlock while lookup and deletion may lead to it if lookup has locked the parent of nodes being coalescenced.