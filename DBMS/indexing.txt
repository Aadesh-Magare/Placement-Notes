//heap file (pile):
records in file are stored one after another simply, no ordering. for deletion mark some bit in record as deleted. searching is brute force.

//sequnetial files :
records are kept in sequential order of some attribute. (generally primary key)
searching is easy since you can do binary search on records within one block, when that block is brought into memory.

for easy insertion and deletion, we can keep a field "next" which will point to next record from current one, this allows the records to be physically inserted anywhere and still be in sequence.

but after frequent insertion deletion in this case, the logical sequnce will be maintained but physically files will be distant, so increase block accesss, so reorganization is required. that will rearrange the records, such function must be done when system is idle

to utilize the deleted space, we can keep the available list, which will have pointers to deleted records.

//the idea is maintain an index above this sequential files, so that the operations on it maybe optimized

index is smaller file (sorted order), that points to items in actual files

//indices are used to find items easily, two type:

1. ordered indices. 
2. hashed indices.

//ordered index: a file can have diff indices corresponding to diff search keys, if the files which contain records are sequentially ordered then the index whoes search key is determining the order of files is called primary index, its also called 	ering index. indeces whoes search key has order diff from order of files are called secondary indices or non clustering indices.

the files in ordered sequence is called index-sequential files.

//Dense and sparse indices:
dense : index contains entry for each search-key, take up more space, searching is fast
 
sparse : index contains entry for some of search keys only, take up less space, insertion deletion overhead is there.

good tradeoff between two is to use sparse with one entry per block, since most of time is for accessing data block on disk, once a block is loaded searching in it is not that costly, so as long as we keep block access to one only it works.

//frequent insertion and deletion may destort the ordering of index file as well so reorganisation is required

//multilevel indices : using indirection
sometimes indices become so large that it has to be stored on disk, if that takes more blocks on disk then searching it becomes costlier, so we use secondary indices for this index file using indirection technique

Indices with two or more levels are called multilevel indices

//indexing on secondary key : cause we may have queries where we dont want to search on primary key but on any other attribute, so its better to have indexing on secondary key as well

//secondary indices dosnt have the same ordering as the records in the file, so its not enough to save pointer to first entry of each search key(cause the records in file are sorted on primary key and not secondary key). so we must save pointer to every entry associated with search key. we can use indirection here, secondary indices will point to a block which in turn will point to all entries associated with that key

so secondary indices must be dense type

///////////////////////////B+ trees///////////////////////////////////////////////

so structure of B+ node is :

imposes insertion, deletion and space overhead but its acceptable when its advantages are taken into account

when its n order tree:

a node (internal) contains n-1 values (search key values on which indexing is done) and n pointers


in case of leaf node the pointer (Pi) will directly point to that particular record (or that block) with search key (Ki) inside the file, if its unique search key (dense indexing). if its not then Pi will point to bucket of pointers that will further point to records

all index nodes (non-leaf) must have at least ceil(n/2) nodes pointers (non-null).

each node is of size of block. all leaf nodes are at same depth 


insertion and deletion in case of B+ trees


//B tree
b tree is slightly more complex than B+.
here internal nodes also store values as opposed to b+ trees.
so a node will contains pointers to keys less than its key, greater than its key jsut like B+ tree but also it will contain direct pointer to record with search key equal to its value


//Hashing
in sequential file indexing we need to access index file, that involves disk access, which degrades performance

a hash function will hash an record into address of corresponding block or bucket.
hash function must be random and uniform

//Bucket Overflow:
It can occure due to: 
1.insufficient buckets 
2. Bucket skew (more entries in a bucket even if others have space)


two types of hashing:
1.closed hashing : in case of overflow, chaining is used (overflow buckets are used for chaining)
2.open hashing: in case of overflow, technique like linear probing is used, or computing further hash


static hashing : since the hash function is fixed, the no of buckets is fixed. over time it becomes inefficent since if buckets are large theres's memory waste otherwise there is lot of clashing.

Dynamic hashing: allow modification of hash function to accomodate change in database

// ordered index files vs hashing
the choice depends on database requirements
hashing is very inefficient for range queries, so its used only when dbms has very rare range queries otherwise ordered indexing is used