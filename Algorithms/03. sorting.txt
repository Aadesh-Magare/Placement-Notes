Internal sorting : sorting data in ram
external sorting : sorting data on disk, huge data that cant fit in ram
	e.g. merge sort like algorithm, divide the file into chunks that can fit in ram and sort those chunks using some sorting algorithm, then using merge like step merge those chunks to get final sorted output.

	it uses n-way merge, ie. take some data from all such sorted chunks and output sorted sequence to disk.

in-place sorting :  which doesn't need extra space i.e. small(constant) extra space is used by algorithm
stable sorting : for similar elements, same order is maintained as that of input

// Classic Bubble Sort:

	compare two elements and swap if out of order, after each iteration largest element is at it's right place at the end of array.
	no of comparisons after each iterations are n-1, n-2, n-3 ...1
	n^2 complexity
	for(i = 0; i < n; i++)
		for(j = 0; j < n-i; j++)

	Improved Bubble sort:

	it checks if during a iteration no swaps are done that means array is completely sorted and no need to continue further
	maintain a exchange variable initially false, during iteration if a swap happens turn it to true if exchange is false break out of loop

// Selection Sort:

	select the min element in array and put it in its proper place, go on doing it

	no way to improve it like bubble sort

// Insertion Sort:
	go on taking a element and insert the element into its proper place.

	insertion sort is efficient if the array is almost sorted, whenever the the array is sorted we have to do only one comparison for the next element to insert. so its just like linear.

// Shell sort
	divide the array into sub-arrays.
	take interval as inc
	if inc = 4
	then sub arrays will be
	original array : index 1 to 10
	sub arrays :
		indexes : 
					1 5 9
					2 6 10
					3 7 
					4 8
	sort these sub arrays
	repeat this till you get inc size as 1 (go on reducing inc after each pass)
	involves insertion sort internally, the complexity is n^1.5

//Bucket Sort (counting sort)

	the hashing sort O(n) thats regularly used is called bucket sort.
	it uses hashing instead of comparisons and puts results into buckets, it may use linked list to store elements within the bucket

	if there are K buckets then its O(n+k) since k is small it becomes O(n)

//Radix sort
	sort numbers based on their digits, starting frm lsb to msb internally it can use any stable sorting technique 
	stable sort = 223 233 if these two are being sorted on unit place then they must appear in same order 223, 233 as they were originally

	if the max no in array has n bits :
		for(i = 0; i < n; i++){
			countingsort(arr, size, i)
		}

	counting sort will sort the array on ith digit of every no, its needed to be stable sort.
	in counting sort here we need to check ith bit of every no, so to obtain ith bit of no k :
		divide k by ith power of 10.
		233563 get 2nd bit of this no

		233563/100 = 2335 now take mod by 10 = 5

			void countSort(int arr[], int n, int index){
				
				int exp = pow(10, index)
			    int output[n]; // output array
    			int i, count[10] = {0};
				
				// Store count of occurrences in count[]
			    for (i = 0; i < n; i++)
			        count[ (arr[i]/exp)%10 ]++;
			 
			    // Change count[i] so that count[i] now contains actual position of
			    // this digit in output[]
			    for (i = 1; i < 10; i++)
			        count[i] += count[i - 1];
			 
			    // Build the output array
			    for (i = n - 1; i >= 0; i--)
			    {
			        output[count[ (arr[i]/exp)%10 ] - 1] = arr[i];
			        count[ (arr[i]/exp)%10 ]--;
			    }
			 
			    // Copy the output array to arr[], so that arr[] now
			    // contains sorted numbers according to curent digit
			    for (i = 0; i < n; i++)
			        arr[i] = output[i];
			}
//Binary Tree sort
	construct a binary tree and do inorder traversal, avg its O(nlogn) but in worst case it becomes O(n^2) when its a linked list instead of tree

//Heap sort
	build the max heap from given data
	swap max elment(at root) with the last element in array
	correct the heap by neglecting the last element
	repeat it

//MergeSort
	
	if you want to sort arr(0, n-1)
	then pass arguments to mergesort as 0 & n-1 only dont send n, that complicates things

	//for finding mid :
		mid = l+r / 2 may cause int overflow for large values
		instead you can do l + (r-l)/2
	//Recursive :
		mergesort() recursive call till you get size of 1
		then 
		merge(arr, low, mid, high)
		merge will merge the two sorted halves into single array and return it

		it requires O(n) extra space to merge
	//Iterative:
		Merge subarrays in bottom up manner, like merge array of size 1 to form that of 2, then that of 4 etc.
		maintain current size of subarray, that would vary from 1 to <= n and double after each pass
		find left starting point and right starting point (mid + 1) along with end points and simply call the usual merge operation
		left_start = it will begin from 0 and increment by current_size * 2 till its n-1
		mid = it would be left_start + current_size -1 
		right_start = mid + 1
		right_end = min of left_start + 2 * current size - 1 and n-1

		void mergesort(int *arr, int low, int high){
			int size, left;
			for(size = 1; size <= high; size *= 2){
					for(left = 0; left < high; left += size*2){
						int mid = left + size -1;
						int right = MIN(left + 2 * size - 1, high);
						merge(arr, left, mid, right);
					}
				}
		}


//QuickSort:
	take a pivot element (first)
	partition the array into two halves, less than pivot on one side and greater then pivot on another, doing so place the pivot at its proper place by swapping
	recursively do same for two arrays thus formed


				void quicksort(int x[10],int first,int last){
				    int pivot,j,temp,i;

				     if(first<last){
				         pivot=first;
				         i=first;
				         j=last;

				         while(i<j){
				             while(x[i]<=x[pivot]&&i<last)
				                 i++;
				             while(x[j]>x[pivot])
				                 j--;
				             if(i<j){
				                 temp=x[i];
				                  x[i]=x[j];
				                  x[j]=temp;
				             }
				         }

				         temp=x[pivot];
				         x[pivot]=x[j];
				         x[j]=temp;
				         quicksort(x,first,j-1);
				         quicksort(x,j+1,last);

				    }
				}

complexity is O(nlogn) worst case is O(n^2) when the data is already sorted.