Essential elements of instruction : opcode (action to be performed), source and destination of operands reference and next instruction reference.

Common architectures makes use of stacks for various features like procedure calls, typically stacks grow from higher addresses to lower addresses.

A machine language expresses operations in basic form involving movement of data to and from registers.

Common architectures involves machine instruction with 0(uses stack) to 4 memory addresses where 4 address instructions are very rare. Most CPU designs involve variety of instruction formats (e.g. having 2 and 3 address instructions)

// Instruction Set characteristics :
    // Types of operands :

        // Addresses : basically unsigned integers
        // Numbers : integer, floating point, Decimal also in some cases.
                Decimal numbers are represented in backed decimal format, using 4 bits for all decimal digits, its less compact since remaining bits are wasted.
        // Characters : mostly represented with ASCII
        // Logical data : individual bits of data are considered.

    // Types of Operators :

        // Data transfer :
            different cases to consider while designing the instructions like transfer from register to register, register to memory, memory to memory, I/O to memory.
        // Arithmatic :
            add, sub, mul, div, absolute, negative, increment, decrement etc
            Most processors provide these instructions for integers but may provide for floating point or packed decimal numbers also.
        // Logical :
            instructions for bit-twiddling.
            Logical shift, Arithmatic shift, rotate etc.
        // Conversion :
            instructions that change format of data e.g. EBCDIC to IRA 
        // Input/ Output:
            deals with I/O devices
        // System Control :
            reserved for operating System
        // Transfer of Control
            e.g. branch, skip and procedure call used in loops, if-else blocks, function calls.

            // Branch : jump instruction.
                most of time its conditional branch.
            // Skip : skip the instruction, usually used with some condition.
                    e.g. ISZ : increment and skip if zero
            // Procedure Call :
                call and return instructions, its form of branch.
                mostly stack is used to store the return address as well as parameters to be passed and returned all these together is called stack frame.

// Addressing Modes :
    
    Most of computer architectures provides more than one addressing modes.
    often different opcodes will use different addressing modes or one or more bits in the instruction format can be used as mode field, which determines which addressing mode is being used.

    The effective address in system without virtual memory is actual physical address or register while in system with virtual memory its virtual address or register.

    // Immediate addressin :
        the operand is actually present in the instruction itself.
        it saves memory reference.
            operand = A

    // Direct addressing :
        the address field in instruction contains effective address of the operand.
        one memory access is required to fetch operand from that location.
            EA = A

    // Indirect addressing :
        the address field in instruction contains intermediate address at which location is the effective address of the operand.
            EA = ( A )

    // Register Addressing :
        the address field in instruction contains register reference instead of memory address (its similar to Direct addressing)
            EA = R
    
    // Register Indirect Addressing :
        similar to indirect addressing, instead of intermediate address, register reference will be provided.
            EA = ( R )

    // Displacement Addressing :
        it requires that instruction has two address fields.
        the value of one field is used directly. The other address field or implicit reference refers to a register whose content is added to first to produce the EA.
            EA = A + ( R )

        // Relative addressing :
            implicitly referenced register is PC, i.e. current instruction address is added to address field to get EA.
            it exploits the locality of reference by assuming that most memory reference are Relatively near to instruction beingn executed.

        // Base-Register addressing :
            The register contains base address and address field contains the displacement.
        
        // Indexing :
            it's same as base-register addressing but with roles swapped.
            The register contains displacement and address field contains the base address.
    
    // Stack addressing :
        stack pointer points to the top of the stack, its maintained in a register. thus reference to stack locations are in fact register indirect addresses.


// Instruction Formats :

    // Instruction length :
        no of opcodes, operands, addressing modes and address ranges affect it.
        It should be equal to memory-transfer length (data-bus length) or one should be multiple of other.    

    // Allocation of Bits :
        for given instruction length there is trade off between number of opcodes and the power of addressing capability.
        
        factors that affect Allocation of bits :

            // Number of addressing modes : some bits are needed for this.
            // Number of operands : more number of operands means fewer bits per operand.
            // Register vs memory : less no of bits are required to specify register.
            // Number of register sets : a register set can be implicit from the opcodes so even fewer bits are needed to select the register in set.
            // address range .
            // address granularity.

    // Variable length instruction :
        increases the complexity of CPU.
        
 
// Instruction Cycle :
    // Indirect Cycle :
        it's part of instruction execution cycle where operands given by indirect addressing are fetched or stored.

    // Data Flow :
        how the data flows from memory to data bus to MBR and address from MAR to address bus

// Instruction Pipelining :

    Instruction prefetch or fetch overlap : next instruction is fetched while current is still being executed.

    Instruction cycle is decomposed into following components for Pipelining :
        FI : fetch instruction
        DI : decode instruction
        CO : calculate operands
        FO : fetch operands
        EI : execute instruction
        WO : write operand

    Issues with Pipelining :
        1. condition branch (or interrupt) , we don't know till the end of this instruction what will be the next instruction so all the Pipelining after this may become useless.
        2. CO may depend on some other register content that has been overwritten due to Pipelining mechanism, this kind of register memory conflicts are a issue.
    
        No of stages in instruction :
            at each stage of the pipeline there are some overhead in moving data from buffer to buffer and performing other preparation and delivery functions. This can have significant effect on execution time of single instruction. hence no of stages of the pipeline cannot be too high even though it may feel like having large no of stages is more efficient.

            The amount of Control logic required to handle the stages increases enormously with number of stages, too many number of stages may make the logic more complx than actual logic of operation.

    // Pipeline Performance :
        cycle time (t) : time needed to advance a set of instructions one stage through pipeline. (time needed to move pipeline by one unit)

        t = maxinum stage delay (tm) + d  (d is time delay of latch)
        k = number of stages in pipeline.
        time to execute all n instructions (Tk) = (k + n-1) * t
        total k cycles are required to complete first instruction and remaining n-1 instructions take n-1 cycles.

                speedup factor = nk / ((n-1) + k)
    
    // Dealing with Branches :

        // multiple streams :
            allow the pipeline to fetch both instruction at the point of branch, making use of two streams.
            // issue with this approach :
                1. increased contention delay for access to registers and memory by both streams
                2. recursive nature of problem i.e. if the prefetched instruction is conditional it will again require two streams.

        // Prefetch branch target :
            when conditional branch is found, its target is prefetched in addition to the next instruction. the target is saved till branch instruction is executed.

        // Loop buffer :
            small, high speed memory maintained by instruction fetch stage of pipeline, it contains n most recently fetched instructions in sequence.

            the buffer will contain next few instructions of the current executing instruction thus branch not taken condition is taken care of.
            if branch occurs to a target just few instructions ahead of current instruction, the target may be present in buffer already.
            for loops its possible that entire loop instructions are already present in the buffer.

        // Branch prediction:
            predict whether the branch will be taken or not
            1. Predict never taken
            2. Predict always taken
                in paged system prefetching the branch target is likely to cause page fault than prefetching next instruction, this should be taken into account while deciding the approach.
            3. Predict by opcde : assume that for certain opcodes branch will be always taken while for some it won't be, so decide it by looking at opcode.
            4. Taken / not taken switch 
            5. Branch history table
                both these approaches predict the branch outcome by monitoring its past behaviour. some of implementations store the branch instruction, couple of history bits and target address in a table, this table is used to decide prefetching.

        // Delayed branch :
            pipeline Performance can be improved by automatically rearranging instructions within program such that branch instructions occur later than actually desired.

        